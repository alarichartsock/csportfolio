## Encoding

64 bit computers work with 64 binary digits at a time, this means that most modern laptops work with 9.2 quintillion numbers at a time. When I first did this calculation, I had to redo it a couple of times because I was absolutely astonished at our modern computing power.

Floating point numbers are a data type in which the "decimal" value is able to float around. The standard convention is the IEEE 754 standard, which calls for scientific notation-like convention.

IEE number:

0.6259 x 10^3

In this case, 0.6259 is the significand and 3 is the exponent.

In a 32 bit floating point number, the first bit is the sign (positive or negative). The next is the exponent (8 bits), and the resulting 23 bits are used to store the significand.

62590 is 01000101110000111001100000000000 as a floating point number.

https://www.h-schmidt.net/FloatConverter/IEEE754.html

ASCII Codes:

https://upload.wikimedia.org/wikipedia/commons/thumb/1/1b/ASCII-Table-wide.svg/875px-ASCII-Table-wide.svg.png

Unicode is another encoding system

https://home.unicode.org/

